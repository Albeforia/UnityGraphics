// Copied & modified from ColorPyramid.compute

#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Color.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Filtering.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Lighting/VolumetricLighting/VBuffer.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/VolumeRendering.hlsl"

#pragma only_renderers d3d11 playstation xboxone xboxseries vulkan metal switch
#pragma enable_d3d11_debug_symbols

#pragma kernel BloomTest
#pragma kernel Upsample
#pragma kernel Scattering
#pragma kernel BilateralBlur
#pragma kernel BilateralPrefilter

#define GROUP_SIZE 8

TEXTURE2D_X(_Input);
float4 _InputSize;

RW_TEXTURE2D_X(float3, _Output);
RW_TEXTURE2D_X(float4, _OutputColor);
TEXTURE3D(_VBufferLighting);

// 16x16 pixels with an 8x8 center that we will be blurring writing out. Each uint is two color
// channels packed together.
// The reason for separating channels is to reduce bank conflicts in the local data memory
// controller. A large stride will cause more threads to collide on the same memory bank.
groupshared uint gs_cacheR[128];
groupshared uint gs_cacheG[128];
groupshared uint gs_cacheB[128];

float3 BlurPixels(float3 a, float3 b, float3 c, float3 d, float3 e, float3 f, float3 g, float3 h, float3 i)
{
    return 0.27343750 * (e    )
         + 0.21875000 * (d + f)
         + 0.10937500 * (c + g)
         + 0.03125000 * (b + h)
         + 0.00390625 * (a + i);
}

void Store2Pixels(uint index, float3 pixel1, float3 pixel2)
{
    gs_cacheR[index] = f32tof16(pixel1.r) | f32tof16(pixel2.r) << 16;
    gs_cacheG[index] = f32tof16(pixel1.g) | f32tof16(pixel2.g) << 16;
    gs_cacheB[index] = f32tof16(pixel1.b) | f32tof16(pixel2.b) << 16;
}

void Load2Pixels(uint index, out float3 pixel1, out float3 pixel2)
{
    uint rr = gs_cacheR[index];
    uint gg = gs_cacheG[index];
    uint bb = gs_cacheB[index];
    pixel1 = float3(f16tof32(rr      ), f16tof32(gg      ), f16tof32(bb      ));
    pixel2 = float3(f16tof32(rr >> 16), f16tof32(gg >> 16), f16tof32(bb >> 16));
}

void Store1Pixel(uint index, float3 pixel)
{
    gs_cacheR[index] = asuint(pixel.r);
    gs_cacheG[index] = asuint(pixel.g);
    gs_cacheB[index] = asuint(pixel.b);
}

void Load1Pixel(uint index, out float3 pixel)
{
    pixel = asfloat(uint3(gs_cacheR[index], gs_cacheG[index], gs_cacheB[index]));
}

// Blur two pixels horizontally. This reduces LDS reads and pixel unpacking.
void BlurHorizontally(uint outIndex, uint leftMostIndex)
{
    float3 s0, s1, s2, s3, s4, s5, s6, s7, s8, s9;
    Load2Pixels(leftMostIndex + 0, s0, s1);
    Load2Pixels(leftMostIndex + 1, s2, s3);
    Load2Pixels(leftMostIndex + 2, s4, s5);
    Load2Pixels(leftMostIndex + 3, s6, s7);
    Load2Pixels(leftMostIndex + 4, s8, s9);

    Store1Pixel(outIndex    , BlurPixels(s0, s1, s2, s3, s4, s5, s6, s7, s8));
    Store1Pixel(outIndex + 1, BlurPixels(s1, s2, s3, s4, s5, s6, s7, s8, s9));
}

void BlurVertically(uint2 pixelCoord, uint topMostIndex)
{
    float3 s0, s1, s2, s3, s4, s5, s6, s7, s8;
    Load1Pixel(topMostIndex     , s0);
    Load1Pixel(topMostIndex +  8, s1);
    Load1Pixel(topMostIndex + 16, s2);
    Load1Pixel(topMostIndex + 24, s3);
    Load1Pixel(topMostIndex + 32, s4);
    Load1Pixel(topMostIndex + 40, s5);
    Load1Pixel(topMostIndex + 48, s6);
    Load1Pixel(topMostIndex + 56, s7);
    Load1Pixel(topMostIndex + 64, s8);

    float3 blurred = BlurPixels(s0, s1, s2, s3, s4, s5, s6, s7, s8);

    // Guard bands
    blurred *= all(pixelCoord < uint2(_InputSize.xy));

    // Write to the final target
    _Output[COORD_TEXTURE2D_X(pixelCoord)] = blurred;
}


[numthreads(GROUP_SIZE, GROUP_SIZE, 1)]
void BloomTest(uint2 groupId : SV_GroupID, uint2 groupThreadId : SV_GroupThreadID, uint3 dispatchThreadId : SV_DispatchThreadID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(dispatchThreadId.z);
    // _Output[COORD_TEXTURE2D_X(dispatchThreadId.xy)] = _Input[COORD_TEXTURE2D_X(dispatchThreadId.xy)];
    // return;

    // Upper-left pixel coordinate of quad that this thread will read
    int2 threadUL = (groupThreadId << 1) + (groupId << 3) - 4;

// #if DOWNSAMPLE
    float2 offset = float2(threadUL);
    float2 maxCoord = 1.0 - 0.5f * _InputSize.zw;
    float3 p00 = SAMPLE_TEXTURE2D_X_LOD(_Input, s_linear_clamp_sampler, ClampAndScaleUVForBilinearPostProcessTexture((offset                    + 0.5) * _InputSize.zw, _InputSize.zw), 0.0).xyz;
    float3 p10 = SAMPLE_TEXTURE2D_X_LOD(_Input, s_linear_clamp_sampler, ClampAndScaleUVForBilinearPostProcessTexture((offset + float2(1.0, 0.0) + 0.5) * _InputSize.zw, _InputSize.zw), 0.0).xyz;
    float3 p01 = SAMPLE_TEXTURE2D_X_LOD(_Input, s_linear_clamp_sampler, ClampAndScaleUVForBilinearPostProcessTexture((offset + float2(0.0, 1.0) + 0.5) * _InputSize.zw, _InputSize.zw), 0.0).xyz;
    float3 p11 = SAMPLE_TEXTURE2D_X_LOD(_Input, s_linear_clamp_sampler, ClampAndScaleUVForBilinearPostProcessTexture((offset + float2(1.0, 1.0) + 0.5) * _InputSize.zw, _InputSize.zw), 0.0).xyz;
// #else
//     uint2 uthreadUL = uint2(max(0, threadUL));
//     uint2 size = uint2(_InputSize.xy) - 1u;
//     float3 p00 = _Input[COORD_TEXTURE2D_X(min(uthreadUL + uint2(0u, 0u), size))].xyz;
//     float3 p10 = _Input[COORD_TEXTURE2D_X(min(uthreadUL + uint2(1u, 0u), size))].xyz;
//     float3 p11 = _Input[COORD_TEXTURE2D_X(min(uthreadUL + uint2(1u, 1u), size))].xyz;
//     float3 p01 = _Input[COORD_TEXTURE2D_X(min(uthreadUL + uint2(0u, 1u), size))].xyz;
// #endif

    // Store the 4 downsampled pixels in LDS
    uint destIdx = groupThreadId.x + (groupThreadId.y << 4u);
    Store2Pixels(destIdx     , p00, p10);
    Store2Pixels(destIdx + 8u, p01, p11);

    GroupMemoryBarrierWithGroupSync();

    // Horizontally blur the pixels in LDS
    uint row = groupThreadId.y << 4u;
    BlurHorizontally(row + (groupThreadId.x << 1u), row + groupThreadId.x + (groupThreadId.x & 4u));

    GroupMemoryBarrierWithGroupSync();

    // Vertically blur the pixels in LDS and write the result to memory
    BlurVertically(dispatchThreadId.xy, (groupThreadId.y << 3u) + groupThreadId.x);
}

TEXTURE2D_X(_InputLowTexture);
TEXTURE2D_X(_InputHighTexture);

RW_TEXTURE2D_X(float3, _OutputTexture);

CBUFFER_START(cb0)
    float4 _Params;                 // x: scatter, yzw: unused
    float4 _BloomBicubicParams;     // xy: low src size, zw: low src texel size
    float4 _TexelSize;              // xy; high src size, zw: high src texel size
CBUFFER_END

#define Scatter     _Params.x

#define GROUP_SIZE 8

[numthreads(GROUP_SIZE, GROUP_SIZE, 1)]
void Upsample(uint3 dispatchThreadId : SV_DispatchThreadID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(dispatchThreadId.z);
    PositionInputs posInputs = GetPositionInput(float2(dispatchThreadId.xy), _TexelSize.zw, uint2(GROUP_SIZE, GROUP_SIZE));
    float2 uv = ClampAndScaleUVPostProcessTexture(posInputs.positionNDC, _BloomBicubicParams.zw, 1.0f);
    float3 highRes = LOAD_TEXTURE2D_X(_InputHighTexture, clamp(posInputs.positionSS, 0, _TexelSize.xy - 1)).xyz;

#if LOW_QUALITY
    float3 lowRes = SAMPLE_TEXTURE2D_X_LOD(_InputLowTexture, s_linear_clamp_sampler, uv, 0.0).xyz;
#else // HIGH_QUALITY
    float2 maxCoord = (1.0f - _TexelSize.zw) * _RTHandlePostProcessScale.xy;
    float3 lowRes = SampleTexture2DBicubic(TEXTURE2D_X_ARGS(_InputLowTexture, s_linear_clamp_sampler), uv, _BloomBicubicParams, maxCoord, unity_StereoEyeIndex).xyz;
#endif

    float3 output = lerp(highRes, lowRes, Scatter);

    // Guard bands
    output *= all(dispatchThreadId.xy <= uint2(_TexelSize.xy));

    _OutputTexture[COORD_TEXTURE2D_X(dispatchThreadId.xy)] = output;
}

TEXTURE2D_X(_InputColorBuffer);
// TEXTURE2D_X(_DensityBuffer);
// float4 _DensityBufferSize;

float _DepthScale;
float _DensityScale;
float _MaxFogDistance2;

void EvaluateAtmosphericScattering2(PositionInputs posInput, float3 V, out float3 color, out float3 opacity)
{
    color = opacity = 0;

    // TODO: do not recompute this, but rather pass it directly.
    // Note1: remember the hacked value of 'posInput.positionWS'.
    // Note2: we do not adjust it anymore to account for the distance to the planet. This can lead to wrong results (since the planet does not write depth).
    float fogFragDist = distance(posInput.positionWS, GetCurrentViewPosition());

    if (_FogEnabled)
    {
        float4 volFog = float4(0.0, 0.0, 0.0, 0.0);

        float expFogStart = 0.0f;

        if (_EnableVolumetricFog != 0)
        {
            bool doBiquadraticReconstruction = _VolumetricFilteringEnabled == 0; // Only if filtering is disabled.
            float4 value = SampleVBuffer(TEXTURE3D_ARGS(_VBufferLighting, s_linear_clamp_sampler),
                                         posInput.positionNDC,
                                         fogFragDist,
                                         _VBufferViewportSize,
                                         _VBufferLightingViewportScale.xyz,
                                         _VBufferLightingViewportLimit.xyz,
                                         _VBufferDistanceEncodingParams,
                                         _VBufferDistanceDecodingParams,
                                         true, doBiquadraticReconstruction, false);

            // TODO: add some slowly animated noise (dither?) to the reconstructed value.
            // TODO: re-enable tone mapping after implementing pre-exposure.
            volFog = DelinearizeRGBA(float4(/*FastTonemapInvert*/(value.rgb), value.a));
            expFogStart = _VBufferLastSliceDist;
        }

        // TODO: if 'posInput.linearDepth' is computed using 'posInput.positionWS',
        // and the latter resides on the far plane, the computation will be numerically unstable.
        float distDelta = fogFragDist - expFogStart;

        if ((distDelta > 0))
        {
            // Apply the distant (fallback) fog.
            float3 positionWS = GetCurrentViewPosition() - V * expFogStart;
            float  startHeight = positionWS.y;
            float  cosZenith = -V.y;

            // For both homogeneous and exponential media,
            // Integrate[Transmittance[x] * Scattering[x], {x, 0, t}] = Albedo * Opacity[t].
            // Note that pulling the incoming radiance (which is affected by the fog) out of the
            // integral is wrong, as it means that shadow rays are not volumetrically shadowed.
            // This will result in fog looking overly bright.

            float3 volAlbedo = _HeightFogBaseScattering.xyz / _HeightFogBaseExtinction;
            float  odFallback = OpticalDepthHeightFog(_HeightFogBaseExtinction, _HeightFogBaseHeight,
                _HeightFogExponents, cosZenith, startHeight, distDelta);
            float  trFallback = TransmittanceFromOpticalDepth(odFallback);
            float  trCamera = 1 - volFog.a;

            // TODO: support for color
            // volFog.rgb += trCamera * GetFogColor(V, fogFragDist) * GetCurrentExposureMultiplier() * volAlbedo * (1 - trFallback);
            volFog.a = 1 - (trCamera * trFallback);
        }

        color = volFog.rgb; // Already pre-exposed
        opacity = volFog.a;
    }
}

float _ScatterStartDistance;
float4 _Curve;
float _DensityPower;
TEXTURE2D_X(_ParticleFogBuffer);

float _UseInscatteringInsteadOfOpacity;

// Absolutely not PBR :)
float GetVisualOfDensity(uint2 coordSS)
{
    float rawDepth = LoadCameraDepth(coordSS).r;
    PositionInputs posInput = GetPositionInput(coordSS, _ScreenSize.zw, rawDepth, UNITY_MATRIX_I_VP, UNITY_MATRIX_V);
    float3 V = GetWorldSpaceNormalizeViewDir(posInput.positionWS);

    float3 fogColor;
    float3 fogOpacity;
    float density;
    EvaluateAtmosphericScattering2(posInput, V, fogColor, fogOpacity);

    if (_UseInscatteringInsteadOfOpacity)
        density = Luminance(fogColor);
    else
        density = fogOpacity.x;

    float additionalFogparticleDensity = saturate(Luminance(_ParticleFogBuffer[COORD_TEXTURE2D_X(coordSS.xy)]));
    density = saturate(density - _Curve.x);

    density = pow(density, _DensityPower);

    density = saturate(density + additionalFogparticleDensity);

    return density * _DensityScale;
}

[numthreads(GROUP_SIZE, GROUP_SIZE, 1)]
void Scattering(uint3 dispatchThreadId : SV_DispatchThreadID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(dispatchThreadId.z);

    // TODO: implement scattering color?
    float3 color;
    float4 inputColor = _InputColorBuffer[COORD_TEXTURE2D_X(dispatchThreadId.xy)];
    float3 blurColor = _Input[COORD_TEXTURE2D_X(dispatchThreadId.xy)].rgb;

    float d = GetVisualOfDensity(dispatchThreadId.xy);
    // float t = density * _DensityScale;
    color.rgb = lerp(inputColor.rgb, blurColor, saturate(d));

    _OutputColor[COORD_TEXTURE2D_X(dispatchThreadId.xy)] = float4(color, inputColor.a); // keep alpha
    // _OutputColor[COORD_TEXTURE2D_X(dispatchThreadId.xy)] = float4(blurColor, inputColor.a); // keep alpha
    // _OutputColor[COORD_TEXTURE2D_X(dispatchThreadId.xy)] = float4(t.xxx, inputColor.a); // keep alpha
}

struct BilateralData
{
    float fogDensity;
    float z01;
};

BilateralData TapBilateralData(uint2 coordSS)
{
    BilateralData key;

    float d = GetVisualOfDensity(coordSS);
    float rawDepth = LoadCameraDepth(coordSS).r;

    key.fogDensity = saturate(d);
    key.z01 = Linear01Depth(rawDepth, _ZBufferParams);

    return key;
}

float _EnableBlurDepthTest;

float ComputeBilateralWeight(BilateralData center, BilateralData tap)
{
    float depthWeight = 1.0;

    depthWeight = max(0.0, 1.0 - abs(tap.fogDensity - center.fogDensity));

    if (_EnableBlurDepthTest)
    {
        if (center.z01 - tap.z01 > 0.1)
            depthWeight = 0;
    }

    return depthWeight;
}

float4 _BlurDirection;
float _Radius;

#define BILATERAL_FILTER_SIGMA 0.9

float sqr(float value)
{
    return value * value;
}
float gaussian(float radius, float sigma)
{
    return exp(-sqr(radius / sigma));
}

[numthreads(8, 8, 1)]
void BilateralBlur(uint3 dispatchThreadId : SV_DispatchThreadID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(dispatchThreadId.z);

    // Fetch the current pixel coordinate
    uint2 centerCoord = dispatchThreadId;

    // Based on which pass of the filter we are doing, adjust the sampling direction
    const uint2 passIncr = uint2(_BlurDirection.xy);

    uint2 geometrCoords = centerCoord;
    // Tap the central pixel coordinates
    const BilateralData center = TapBilateralData(geometrCoords);

    float radius = _Radius * GetVisualOfDensity(centerCoord);
    const float sigma =  radius * BILATERAL_FILTER_SIGMA;
    const int effectiveRadius = min(sigma * 2.0, radius);

    // Store the intermediate result
    float4 originalPixel = LOAD_TEXTURE2D_X(_Input, centerCoord);
    float3 finalColor = originalPixel.rgb;

    // Initialize variables for accumulation
    float3 colorSum = float3(0.0, 0.0, 0.0);
    float wSum = 0.0;

    int2 tapCoord = centerCoord - effectiveRadius * passIncr;
    for (int r = -effectiveRadius; r <= effectiveRadius; ++r, tapCoord += passIncr)
    {
        // Make sure the pixel coord we are trying to use is in the screen (not out of bounds)
        if (tapCoord.x >= _ScreenSize.x || tapCoord.x < 0 || tapCoord.y >= _ScreenSize.y || tapCoord.y < 0)
            continue;

        // Compute the weight (skip computation for the center)
        const BilateralData tapData = TapBilateralData(tapCoord);
        float w = r ? gaussian(r, sigma) * ComputeBilateralWeight(center, tapData) : 1.0;
        colorSum += LOAD_TEXTURE2D_X(_Input, tapCoord).xyz * w;
        wSum += w;
    }
    // Normalize the result
    finalColor = colorSum / wSum;

    _Output[COORD_TEXTURE2D_X(centerCoord)] = float4(finalColor, originalPixel.a);
}

half3 Median(half3 a, half3 b, half3 c)
{
    return a + b + c - min(min(a, b), c) - max(max(a, b), c);
}

[numthreads(8, 8, 1)]
void BilateralPrefilter(uint3 dispatchThreadId : SV_DispatchThreadID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(dispatchThreadId.z);

    float3 d = float3(1, 1, 0);
    half4 s0 = _Input[COORD_TEXTURE2D_X(dispatchThreadId.xy)];
    half3 s1 = _Input[COORD_TEXTURE2D_X(dispatchThreadId.xy - d.xz)].rgb;
    half3 s2 = _Input[COORD_TEXTURE2D_X(dispatchThreadId.xy + d.xz)].rgb;
    half3 s3 = _Input[COORD_TEXTURE2D_X(dispatchThreadId.xy - d.zy)].rgb;
    half3 s4 = _Input[COORD_TEXTURE2D_X(dispatchThreadId.xy + d.zy)].rgb;
    half3 m = Median(Median(s0.rgb, s1, s2), s3, s4);

    _Output[COORD_TEXTURE2D_X(dispatchThreadId.xy)] = m;
}