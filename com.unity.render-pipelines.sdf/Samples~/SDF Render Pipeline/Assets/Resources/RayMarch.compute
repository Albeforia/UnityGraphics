
#pragma enable_d3d11_debug_symbols
#pragma kernel RayMarchKernel

#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"

//#define DEG_TO_RAD 0.017453292519943295
#define MAX_STEPS 64
#define IDENTITY_MATRIX float4x4(1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1)



//CBUFFER_START(CameraDetails)
    float4x4 InvViewProjectionMatrix;
    float4x4 InvViewMatrix;
    float4x4 InvProjectionMatrix;
    float3  CameraPos;
    int pad;
    float4 TexelSize;
    float3 Soner_Debug;
//CBUFFER_END


struct ObjectHeader
{
    float4x4 worldToObjMatrix;
    float4   color;
    int      objID;
    int      numEntries;
    int      startOffset;
    int      normalsOffset;
    float3   minExtent;
    float    voxelSize;
    float3   maxExtent;
    float    pad1;
};

// This will have the actual sdf data in a contiguous array. Right now we store everything in the scene here, but will need to optimize it
StructuredBuffer<float> _ObjectSDFData : register(t1);

// Header data to index into the above actual sdf data
StructuredBuffer<ObjectHeader> _ObjectHeaderData : register (t2);

// Voxel Count X Axis = 8
// Voxel Count Y Axis = 8
// Voxel Count Z Axis = 1
// Voxel Size = 0.25
// Mesh Min Bounds Extents = (-1.0, -1.0, 0.0)
// Mesh Max Bounds Extents = (1.0, 1.0, 0.0)
//float _ObjectSDFData[64] =
//{
//0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f,
//0.0559017f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0559017f,
//0.1677051f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.1677051f,
//0.2795085f, 0.0559017f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0559017f, 0.2795085f,
//0.3913119f, 0.1677051f, 0.0f, 0.0f, 0.0f, 0.0f, 0.1677051f, 0.3913119f,
//0.5031153f, 0.2795085f, 0.0559017f, 0.0f, 0.0f, 0.0559017f, 0.2795085f, 0.5031153f,
//0.6149187f, 0.3913119f, 0.1677051f, 0.0f, 0.0f, 0.1677051f, 0.3913119f, 0.6149187f,
//0.7267221f, 0.5031153f, 0.2795085f, 0.0559017f, 0.0559017f, 0.2795085f, 0.5031153f, 0.7267221f,
//};
//ObjectHeader _ObjectHeaderData[1];

// Tile Data
// This will store contiguous data for each tile. It will be contiguous data and the boundaries for each tile will be represented by the TileObjectHeader.
// This will store the list of offsets into _ObjectHeaderData for a specific tile.
StructuredBuffer<int> _TileDataOffsetIntoObjHeader : register(t3);

// Stores the offset into the _TileDataOffsetIntoHeader. Also has number of objects for each tile.
// This will have an entry for each tile of screen. Each threadgroup can read one value (if tile size and numthreads are the same)
struct TileDataHeader
{
	int  offset;
	int  numObjects;
	int2 pad;
};
StructuredBuffer<TileDataHeader> _TileDataHeader : register(t4);

// Index into using ObjectHeader.normalsOffset
StructuredBuffer<float3> _Normals : register(t5);

struct IntersectionData
{
    float t;
    float3 normal;
    float4 color;
};

struct OutSdfData
{
    int objID;
    IntersectionData intersection;
};
RWStructuredBuffer<OutSdfData> g_OutSdfData : register(u0);
RWTexture2D<float4> g_DebugOutput : register(u1);

// https://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm
float sdBox(float3 p, float3 b)
{
    float3 q = abs(p) - b;
    return length(max(q, 0.0)) + min(max(q.x, max(q.y, q.z)), 0.0);
}

struct RayData
{
    float3 direction;
    float3 pointOnPlane;
};

RayData GetRayDirection(int2 currPos, /*float fovHalf,*/ int2 imageSize)
{
 //   float imageAspectRatio = (float)imageSize.x / imageSize.y; // assuming width > height
 //   //float Px = (2 * ((currPos.x + 0.5) / imageSize.x) - 1) * tan(fovHalf * DEG_TO_RAD) * imageAspectRatio;
 //   //float Py = (2 * ((currPos.y + 0.5) / imageSize.y) - 1) * tan(fovHalf * DEG_TO_RAD);

 //   float Px = (2 * ((currPos.x + 0.5) / imageSize.x) - 1);
 //   float Py = (2 * ((currPos.y + 0.5) / imageSize.y) - 1);

 //   float3 rayOrigin = float3(0, 0, 0);

	//float4 rayPointWS = mul(InvProjectionMatrix, float4 (Px, Py, -1, 1));
	//rayPointWS = mul(InvViewMatrix, rayPointWS);
	//if (rayPointWS.w != 0)
	//	rayPointWS /= rayPointWS.w;

 //   float3 rayDirectionWS = SafeNormalize(rayPointWS.xyz - CameraPos);
 //   
 //   //rayDirection.normalize(); // it's a direction so don't forget to normalize 
 //   RayData rayData;
	//rayData.direction = rayPointWS.xyz;// rayDirectionWS;
 //   rayData.pointOnPlane = CameraPos;

 //   return rayData;
	float imageAspectRatio = (float)imageSize.x / imageSize.y;
	//#line 111
	float Px = (2 * ((currPos.x + 0.5) / imageSize.x) - 1);
	float Py = (2 * ((currPos.y + 0.5) / imageSize.y) - 1);

	float3 rayOrigin = float3 (0, 0, 0);

	float4 rayPointWS = mul(InvProjectionMatrix, float4 (Px, Py, -1, 1));
	rayPointWS = mul(InvViewMatrix, rayPointWS);
	if (rayPointWS.w != 0)
		rayPointWS /= rayPointWS.w;

	float3 rayDirectionWS = /*SafeNormalize*/ (rayPointWS.xyz - CameraPos);
	//#line 124
	RayData rayData;
	rayData.direction = rayPointWS.xyz;
	rayData.pointOnPlane = CameraPos;

	return rayData;

}

float Convert3DPosTo1D(float3 pos, int3 voxelSize)
{
	return (pos.x + (pos.y * voxelSize.x) + (pos.z * voxelSize.y * voxelSize.x));
}

IntersectionData RayMarch(int objHeaderOffset, float3 rayPoint, float3 cameraPos)
{
    IntersectionData returnValue;
    ObjectHeader objHeader = _ObjectHeaderData[objHeaderOffset];
    returnValue.color = objHeader.color;

	float3 objBBox = objHeader.maxExtent - objHeader.minExtent;
	float3 dimensions = objBBox / objHeader.voxelSize;
	int3 voxelSize = int3 (ceil(dimensions.x), ceil(dimensions.y), ceil(dimensions.z));

 //   float3 camPosOS = mul(objHeader.worldToObjMatrix, float4(CameraPos, 1)).xyz;
 //   float3 rayDirOS = mul(objHeader.worldToObjMatrix, float4(rayDir, 0)).xyz;
	//rayDirOS = SafeNormalize(rayDirOS);

	float4 rayPointOS = mul(objHeader.worldToObjMatrix, float4 (rayPoint, 1));
	if (rayPointOS.w > 0)
		rayPointOS /= rayPointOS.w;
	float4 camPosOS = mul(objHeader.worldToObjMatrix, float4 (CameraPos, 1));
	if (camPosOS.w > 0)
		camPosOS /= camPosOS.w;
	float3 rayDirOS; // = mul ( objHeader . worldToObjMatrix , float4 ( rayDir , 0 ) ) . xyz ;
	//rayDirOS = SafeNormalize ( rayDirOS ) ;
	rayDirOS = SafeNormalize(rayPointOS.xyz - camPosOS.xyz);

	// Initially test with camera to check how far the object is. This will help determine the step size
    float3 rayPosOS = camPosOS.xyz;

    //float3 newPos = SafeNormalize(rayDirOS) * t;
    float totalDistance = 0.0f;

	float3 minExtent = float3(objHeader.minExtent.x, objHeader.minExtent.y, objHeader.minExtent.z);
	float3 maxExtent = float3(objHeader.maxExtent.x, objHeader.maxExtent.y, objHeader.maxExtent.z);

    for (int i = 0; i < MAX_STEPS; i++)
    {
        // Check if it intersects bounding box
        // Assuming object space origin is cthe object center
        float distance = sdBox(rayPosOS.xyz, objBBox / 2);
        totalDistance += distance;
        float threshold = 0.0001;
        if (abs(distance) < totalDistance * threshold)
        {
            // Has hit bounding box. Check with actual data

			bool outsideHit = false;
			// Tolerance for edge value
			float edgeErrorTolerance = 0.001;
			rayPosOS = camPosOS.xyz + rayDirOS.xyz * totalDistance;
			rayPosOS = clamp(rayPosOS.xyz, minExtent, maxExtent - edgeErrorTolerance);

            for (int j = 0; j < MAX_STEPS; j++)
            {
                if (rayPosOS.x < minExtent.x || rayPosOS.x > maxExtent.x ||
                    rayPosOS.y < minExtent.y || rayPosOS.y > maxExtent.y ||
                    rayPosOS.z < minExtent.z || rayPosOS.z > maxExtent.z)
                {
                    returnValue.t = 0.0f;
                    return returnValue;
                }
                
				int3 voxelPos = floor((rayPosOS - minExtent) / objHeader.voxelSize);

                int linearVoxelPos = Convert3DPosTo1D(voxelPos, voxelSize);
                distance =  _ObjectSDFData[objHeader.startOffset + linearVoxelPos];
                totalDistance += distance;

                if (abs(distance) < totalDistance * threshold)
                {
                    // Found intersection point
                    returnValue.t = totalDistance;
                    returnValue.normal = _Normals[objHeader.normalsOffset + linearVoxelPos];
                    return returnValue;
                }
                else if (distance < 0.0f)
				{
					//if (outsideHit)
					{
						// Ray was outside and now is inside. It shouldn't happen if data is exact but might happen due to errors
						// Handling this case here
                        returnValue.t = totalDistance;
                        return returnValue;
                    }
                    // Ray has gone outside the box. Return as no intersection has been found
                    returnValue.t = 0.0f;
                    return returnValue;
                }

				// The ray is outside the model. To check if it goes from outside to inside the model
				outsideHit = true;
				rayPosOS = camPosOS.xyz + rayDirOS.xyz * totalDistance;
            }

            // No intersection found even after max steps within the bounding box
            returnValue.t = 0.0f;
            return returnValue;
        }

        rayPosOS = camPosOS.xyz + rayDirOS.xyz * totalDistance;
    }

    // Doesn't intersect bounding box
    returnValue.t = -1.0f;
    return returnValue;
}

OutSdfData RayMarchAllObjects(float3 dir, float3 pointOnPlane, TileDataHeader tileDataHeader)
{
    OutSdfData outSdfData;
    outSdfData.intersection.t = 0.0f;
    outSdfData.objID = 0;

    for (int id = 0; id < tileDataHeader.numObjects; ++id)
    {
		int objHeaderOffset = _TileDataOffsetIntoObjHeader[tileDataHeader.offset + id];
        IntersectionData currIntersection = RayMarch(objHeaderOffset, dir, pointOnPlane);
        if (currIntersection.t > 0.0f && (outSdfData.intersection.t <= 0 || currIntersection.t < outSdfData.intersection.t))
        {
            ObjectHeader objHeader = _ObjectHeaderData[objHeaderOffset];
            outSdfData.objID = objHeader.objID;
            outSdfData.intersection = currIntersection;
        }
    }

    // Write to UAV
    return outSdfData;
}

// TODO - Store the object id in the z dimension, so that each group just works on a single object.
// Will need to figure out how to sync and get the minimum value out. Could write to LDS and then sync and use groupID.z == 0 to find minimum. But with so many objects, not sure if it's a good ides.
// Maybe could write it to a UAV and use another dispatch to process the min value - that will ensure all threads retire quickly
[numthreads(8, 8, 1)]
void RayMarchKernel(uint3 dispatchTid : SV_DispatchThreadID, uint3 groupId : SV_GroupID, uint groupIndex : SV_GroupIndex)
{
    int numDispatchesX = ((TexelSize.z + (8 - 1)) / 8);
    int tileIndex = groupId.x + groupId.y * numDispatchesX;
    TileDataHeader tileDataHeader = _TileDataHeader[tileIndex];
    RayData rayData = GetRayDirection(dispatchTid.xy, /*_FieldOfViewBy2,*/ TexelSize.zw);
    OutSdfData outData = RayMarchAllObjects(rayData.direction, rayData.pointOnPlane/*, groupId*/, tileDataHeader);

    // TODO - If using z-dimension for anything else, please change the group index and manually calculate
    g_OutSdfData[groupIndex] = outData;

    // For debug only
    // output ray direction:
    const  int Debug = 3;
    if (Debug == 0)
    {
        g_DebugOutput[dispatchTid.xy] = float4(0, outData.intersection.t, 0, 1.0);
    }
    else if (Debug == 1)
    {
        g_DebugOutput[dispatchTid.xy] = float4((outData.intersection.normal + 1) * 0.5, 1.0);
    }
    else if (Debug == 2)
    {
        g_DebugOutput[dispatchTid.xy] = outData.intersection.color;
    }
    else if (Debug == 3)
    {
        g_DebugOutput[dispatchTid.xy] = outData.objID / 5.0;
    }
    // output ray point on Plane:
    //g_DebugOutput[dispatchTid.xy] = float4((rayData.pointOnPlane.xy + 1)*0.5, 0, 1.0);

    //g_DebugOutput[dispatchTid.xy] = float4(1.0, 0.0, 0.0, 1.0);
}
